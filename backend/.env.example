AI_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
LLM_MODEL=qwen2.5:7b
EMBED_MODEL=mxbai-embed-large
CHROMA_PATH=./chroma_data
DB_URL=postgresql://palo:palo@localhost:5444/palo_rag

# LLM tuning
LLM_TEMPERATURE=0.1

# RAG tuning
TOP_K=4
MIN_RETRIEVAL_SCORE=0.3
LOW_CONFIDENCE_THRESHOLD=0.5
NO_INFO_MESSAGE="Je n'ai pas d'information sur ce sujet dans la base de connaissance."

# Ingestion tuning
CHUNK_SIZE=500
CHUNK_OVERLAP=50

# Guardrails
GUARDRAIL_MAX_LENGTH=500

# API tuning
DEFAULT_LOGS_LIMIT=100
CORS_ALLOW_ORIGINS=http://localhost:4200
